Steps,Policy/Entropy,Environment/Episode Length,Policy/Extrinsic Value Estimate,Environment/Cumulative Reward,Policy/Extrinsic Reward,Losses/Value Loss,Losses/Policy Loss,Policy/Learning Rate,Is Training
10000,1.4441575,4.547420965058237,2.6132667,4.01459546134157,4.01459546134157,45.373566,0.26528838,0.00026977208,1.0
20000,1.48881,3.8560311284046693,1.3815593,3.3520413425156397,3.3520413425156397,2.946947,0.29588044,0.0002099101,1.0
30000,1.5314821,3.755703422053232,1.4793657,3.2643371925317726,3.2643371925317726,1.6667186,0.28600746,0.00014986917,1.0
40000,1.5595313,3.834866828087167,1.361242,3.3319637767350883,3.3319637767350883,0.77360886,0.2861427,8.997777e-05,1.0
50000,1.5720445,3.8823816495851635,1.4568181,3.384326698607765,3.384326698607765,0.270817,0.25040007,3.0036214e-05,1.0
